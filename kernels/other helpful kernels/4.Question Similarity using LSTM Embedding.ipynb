{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../data/train.csv', encoding='utf-8')\n",
    "df_train['id'] = df_train['id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../../data/test.csv', encoding='utf-8')\n",
    "df_test['test_id'] = df_test['test_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_train, df_test))\n",
    "df_all['question1'].fillna('', inplace=True)\n",
    "df_all['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocab ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_vectorizer = CountVectorizer(max_features=10000-1).fit(\n",
    "    itertools.chain(df_all['question1'], df_all['question2']))\n",
    "other_index = len(counts_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Prep Data##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_tokenizer = re.compile(counts_vectorizer.token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_padded_seqs(texts, max_len=10):\n",
    "    seqs = texts.apply(lambda s: \n",
    "        [counts_vectorizer.vocabulary_[w] if w in counts_vectorizer.vocabulary_ else other_index\n",
    "         for w in words_tokenizer.findall(s.lower())])\n",
    "    return pad_sequences(seqs, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = \\\n",
    "    train_test_split(create_padded_seqs(df_all[df_all['id'].notnull()]['question1']), \n",
    "                     create_padded_seqs(df_all[df_all['id'].notnull()]['question2']),\n",
    "                     df_all[df_all['id'].notnull()]['is_duplicate'].values,\n",
    "                     stratify=df_all[df_all['id'].notnull()]['is_duplicate'].values,\n",
    "                     test_size=0.3, random_state=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 9789, 4792, ..., 6308, 5987, 4766],\n",
       "       [   0,    0,    0, ..., 6026, 6517, 4127],\n",
       "       [   0,    0,    0, ..., 6459, 8151, 3860],\n",
       "       ..., \n",
       "       [   0,    0,    0, ..., 3536, 1155, 3731],\n",
       "       [   0,    0, 2804, ...,  295, 2646, 6319],\n",
       "       [   0, 9789, 8985, ..., 7989, 4519, 1572]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Training##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.layers as lyr\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 10, 100)       1000000     input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 256)           365568      embedding_1[0][0]                \n",
      "                                                                   embedding_1[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)            (None, 256)           0           lstm_1[0][0]                     \n",
      "                                                                   lstm_1[1][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 16)            4112        multiply_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             17          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,369,697\n",
      "Trainable params: 1,369,697\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1_tensor = lyr.Input(X1_train.shape[1:])\n",
    "input2_tensor = lyr.Input(X2_train.shape[1:])\n",
    "\n",
    "words_embedding_layer = lyr.Embedding(X1_train.max() + 1, 100)\n",
    "seq_embedding_layer = lyr.LSTM(256, activation='tanh')\n",
    "\n",
    "seq_embedding = lambda tensor: seq_embedding_layer(words_embedding_layer(tensor))\n",
    "\n",
    "merge_layer = lyr.multiply([seq_embedding(input1_tensor), seq_embedding(input2_tensor)])\n",
    "\n",
    "dense1_layer = lyr.Dense(16, activation='sigmoid')(merge_layer)\n",
    "ouput_layer = lyr.Dense(1, activation='sigmoid')(dense1_layer)\n",
    "\n",
    "model = Model([input1_tensor, input2_tensor], ouput_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283003 samples, validate on 121287 samples\n",
      "Epoch 1/6\n",
      "149s - loss: 0.5227 - val_loss: 0.4820\n",
      "Epoch 2/6\n",
      "141s - loss: 0.4457 - val_loss: 0.4520\n",
      "Epoch 3/6\n",
      "142s - loss: 0.3963 - val_loss: 0.4345\n",
      "Epoch 4/6\n",
      "142s - loss: 0.3539 - val_loss: 0.4306\n",
      "Epoch 5/6\n",
      "142s - loss: 0.3144 - val_loss: 0.4405\n",
      "Epoch 6/6\n",
      "142s - loss: 0.2765 - val_loss: 0.4506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26adb938780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train], y_train, \n",
    "          validation_data=([X1_val, X2_val], y_val), \n",
    "          batch_size=128, epochs=6, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extract Features From Model##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_model = Model([input1_tensor, input2_tensor], merge_layer)\n",
    "features_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_train = features_model.predict([X1_train, X2_train], batch_size=128)\n",
    "F_val = features_model.predict([X1_val, X2_val], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   3.63397156e-03,   7.08418250e-01, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,  -6.80528535e-03,   1.60586804e-01, ...,\n",
       "          0.00000000e+00,  -0.00000000e+00,  -0.00000000e+00],\n",
       "       [  0.00000000e+00,   4.35364753e-04,  -1.31063564e-02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  2.88876152e-04,   5.03762249e-06,   7.65537173e-02, ...,\n",
       "          0.00000000e+00,   1.04935067e-02,   4.71994560e-03],\n",
       "       [  0.00000000e+00,  -1.22844256e-04,  -6.46804273e-01, ...,\n",
       "         -0.00000000e+00,  -0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   3.02577575e-07,  -5.11572957e-02, ...,\n",
       "          0.00000000e+00,  -0.00000000e+00,   0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train XGBoost##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda2\\envs\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dTrain = xgb.DMatrix(F_train, label=y_train)\n",
    "dVal = xgb.DMatrix(F_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.649218\tval-logloss:0.656476\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 10 rounds.\n",
      "[10]\ttrain-logloss:0.432129\tval-logloss:0.491124\n",
      "[20]\ttrain-logloss:0.349711\tval-logloss:0.445954\n",
      "[30]\ttrain-logloss:0.30302\tval-logloss:0.429475\n",
      "[40]\ttrain-logloss:0.279071\tval-logloss:0.426231\n",
      "[50]\ttrain-logloss:0.258509\tval-logloss:0.426764\n",
      "Stopping. Best iteration:\n",
      "[45]\ttrain-logloss:0.268251\tval-logloss:0.42574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 9,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 1 / F_train.shape[1]**0.5,\n",
    "    'min_child_weight': 5,\n",
    "    'silent': 1\n",
    "}\n",
    "bst = xgb.train(xgb_params, dTrain, 1000,  [(dTrain,'train'), (dVal,'val')], \n",
    "                verbose_eval=10, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Predict Test##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_test = create_padded_seqs(df_all[df_all['test_id'].notnull()]['question1'])\n",
    "X2_test = create_padded_seqs(df_all[df_all['test_id'].notnull()]['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_test = features_model.predict([X1_test, X2_test], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "exception: access violation reading 0x000000E6A11F0000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ffd9107a72d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mE:\\Anaconda2\\envs\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda2\\envs\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[0;34m(self, mat, missing)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                                 \u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                                                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                                 ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: exception: access violation reading 0x000000E6A11F0000"
     ]
    }
   ],
   "source": [
    "dTest = xgb.DMatrix(F_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "        'id': df_all[df_all['id'].notnull()]['id'].values,\n",
    "        'is_duplicate': df_all[df_all['is_duplicate'].notnull()]['is_duplicate'].values\n",
    "    })#.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404260</th>\n",
       "      <td>404260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404261</th>\n",
       "      <td>404261</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404262</th>\n",
       "      <td>404262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404263</th>\n",
       "      <td>404263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404264</th>\n",
       "      <td>404264</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404265</th>\n",
       "      <td>404265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404266</th>\n",
       "      <td>404266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404267</th>\n",
       "      <td>404267</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404268</th>\n",
       "      <td>404268</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404269</th>\n",
       "      <td>404269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404270</th>\n",
       "      <td>404270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404271</th>\n",
       "      <td>404271</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404272</th>\n",
       "      <td>404272</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404273</th>\n",
       "      <td>404273</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404274</th>\n",
       "      <td>404274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404275</th>\n",
       "      <td>404275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404276</th>\n",
       "      <td>404276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404277</th>\n",
       "      <td>404277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404278</th>\n",
       "      <td>404278</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404279</th>\n",
       "      <td>404279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404280</th>\n",
       "      <td>404280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404281</th>\n",
       "      <td>404281</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404282</th>\n",
       "      <td>404282</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404283</th>\n",
       "      <td>404283</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>404284</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_duplicate\n",
       "0            0           0.0\n",
       "1            1           0.0\n",
       "2            2           0.0\n",
       "3            3           0.0\n",
       "4            4           0.0\n",
       "5            5           1.0\n",
       "6            6           0.0\n",
       "7            7           1.0\n",
       "8            8           0.0\n",
       "9            9           0.0\n",
       "10          10           0.0\n",
       "11          11           1.0\n",
       "12          12           1.0\n",
       "13          13           1.0\n",
       "14          14           0.0\n",
       "15          15           1.0\n",
       "16          16           1.0\n",
       "17          17           0.0\n",
       "18          18           1.0\n",
       "19          19           0.0\n",
       "20          20           1.0\n",
       "21          21           0.0\n",
       "22          22           0.0\n",
       "23          23           0.0\n",
       "24          24           0.0\n",
       "25          25           0.0\n",
       "26          26           0.0\n",
       "27          27           0.0\n",
       "28          28           0.0\n",
       "29          29           1.0\n",
       "...        ...           ...\n",
       "404260  404260           0.0\n",
       "404261  404261           1.0\n",
       "404262  404262           0.0\n",
       "404263  404263           0.0\n",
       "404264  404264           0.0\n",
       "404265  404265           1.0\n",
       "404266  404266           0.0\n",
       "404267  404267           1.0\n",
       "404268  404268           0.0\n",
       "404269  404269           0.0\n",
       "404270  404270           0.0\n",
       "404271  404271           0.0\n",
       "404272  404272           1.0\n",
       "404273  404273           1.0\n",
       "404274  404274           1.0\n",
       "404275  404275           0.0\n",
       "404276  404276           0.0\n",
       "404277  404277           0.0\n",
       "404278  404278           0.0\n",
       "404279  404279           0.0\n",
       "404280  404280           1.0\n",
       "404281  404281           1.0\n",
       "404282  404282           1.0\n",
       "404283  404283           0.0\n",
       "404284  404284           1.0\n",
       "404285  404285           0.0\n",
       "404286  404286           1.0\n",
       "404287  404287           0.0\n",
       "404288  404288           0.0\n",
       "404289  404289           0.0\n",
       "\n",
       "[404290 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dbab69aa6a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_sub = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m         \u001b[1;34m'test_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[1;34m'is_duplicate'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     }).set_index('test_id')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dTest' is not defined"
     ]
    }
   ],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "        'test_id': df_all[df_all['test_id'].notnull()]['test_id'].values,\n",
    "        'is_duplicate': bst.predict(dTest, ntree_limit=bst.best_ntree_limit)\n",
    "    }).set_index('test_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub['is_duplicate'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
