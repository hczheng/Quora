{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Here's a quick attempt at exploring why the train set average response rate could be so different to that observed in the Public LB\n\nIf we make the assumption that there's an underlying temporal pattern to the data, and use the qid values as a proxy for it (higher qid value implies more recent question), then re-sorting the train set by increasing qid and plotting the sliding window of mean response rate should show us some pattern.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv( \"../input/train.csv\")\n\ndf[\"qmax\"]      = df.apply( lambda row: max(row[\"qid1\"], row[\"qid2\"]), axis=1 )\ndf              = df.sort_values(by=[\"qmax\"], ascending=True)\ndf[\"dupe_rate\"] = df.is_duplicate.rolling(window=500, min_periods=500).mean()\ndf[\"timeline\"]  = np.arange(df.shape[0]) / float(df.shape[0])\n\ndf.plot(x=\"timeline\", y=\"dupe_rate\", kind=\"line\")\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The above pattern, and the ~16.5% LB response rate reported by others, imply that the Public LB (and possibly Private LB) are potentially sourced from more recent data than the training set.\n\nIf this holds, then we could also use this concept to more appropriately construct validation data splits and training data sampling\n",
      "metadata": {}
    }
  ]
}